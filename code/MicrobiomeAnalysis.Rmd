title: "Microbiome Analysis"
author: "Pankti"
date: "2024-03-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This code is written to practice the workflow for processing and analyzing data from amplicon sequencing experiment. The data used here comes from V4 region of 16s genes. 360 fecal samples were collected from 12 mice over a period of one year to study murine microbiome. The data can be found [here](https://mothur.org/w/images/d/d6/MiSeqSOPData.zip/). 

```{r, echo=F, message=F, warning=F}
library(knitr)
library(microbiome)
library(dada2)
library(DECIPHER)
library(phyloseq)
library(phangorn)
library(gridExtra)
library(ggplot2)
library(phyloseqGraphTest)
library(genefilter)
library(impute)
library(dplyr)
library(reshape2)
library(ade4)
library(nlme)
library(DESeq2)
library(PMA)
library("phyloseqGraphTest")
library("ggnetwork")
library(randomForest)
library(structSSI)
library(igraph)
```



```{r echo=F, message=F, warning=F}
# set.seed(100)
```



```{r, echo=F, message=F, warning=F}
miseq_path <- "../data/MiSeq_SOP/"
# list.files(miseq_path)
```

<font color = "blue">Filter and Trim</font>
To begin with, we filter out the low quality reads. So we plot the data quality first, to see where to filter out in this dataset. Here we plot data from first two samples of forward and reverse reads. 

```{r echo=T, message=F, warning=F}
# Sorting files with forward and reverse reads
fnFs <- sort(list.files(miseq_path, pattern = "_R1_001.fastq")) # Forward reads
fnRs <- sort(list.files(miseq_path, pattern = "_R2_001.fastq")) # Reverse reads

# Extract sample names:
sampleNames <- sapply(strsplit(fnFs, "_"), `[`, 1)

# specifying full paths to the file lists:
fnFs <- file.path(miseq_path, fnFs)
fnRs <- file.path(miseq_path, fnRs)

# quality of first 2 reads. # Most data shows trend of decreasing average quality towards end of the sequencing reads
dada2::plotQualityProfile(fnFs[1:2])
```



```{r, echo=T, message=F, warning=F}
dada2::plotQualityProfile(fnRs[1:2])
```

Here, the forward reads maintain high quality throughout, while the quality of the reverse reads drops significantly at about position 160. Therefore, we choose to truncate the forward reads at position 245, and the reverse reads at position 160. We also choose to trim the first 10 nucleotides of each read based on empirical observations across many Illumina datasets that these base positions are particularly likely to contain pathological errors.

We define the filenames for the filtered fastq.gz files:

```{r echo=T, message=F, warning=F}
filt_path <- file.path(miseq_path, "filtered") # To keep filtered files in filtered directories
if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(filt_path, paste0(sampleNames, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sampleNames, "_R_filt.fastq.gz"))
```



```{r, echo=T, message=F, warning=F}
out <- dada2::filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen = c(240, 160),
                            maxN = 0, maxEE = c(2,2), truncQ = 2, rm.phix = TRUE,
                            compress = T, multithread = T)
# head(out)
```
# Infer Sequence variants
The next step in the workflow is to cluster the sequences based on a arbitrary fixed dissimilarity threshold, however, with DADA2 package, we can get amplicon sequencing variants exactly, with the resolution of one nucleotide (Benjamin J Callahan et al. 2016). 

The sequence data is imported into R from demultiplexed fastq files (i.e. one fastq for each sample) and simultaneously dereplicated to remove redundancy. This done to improve efficiency of computational time. 

# Dereplication
Dereplication combines all identical sequencing reads into “unique sequences” with a corresponding “abundance”: the number of reads with that unique sequence. 
This step is essentially converting the data with sequences into counts that can be used for further analysis.

```{r echo=T, message=F, warning=F}
derepFs <- dada2::derepFastq(filtFs, verbose = T)
derepRs <- dada2::derepFastq(filtRs, verbose = T)

# Name the derep class objects by the sample names
names(derepFs) <- sampleNames
names(derepRs) <- sampleNames
```

Next, we need to distinguish sequencing errors from biological variation and and DADA2 relies on unsupervised learning from the data where sample interference and parameter estimation are alternated with until consistency is seen.  

```{r, echo=T, message=F, warning=F}
errF <- dada2::learnErrors(filtFs, multithread = T)
errR <- learnErrors(filtRs, multithread = T)
```



```{r echo=T, message=F, warning=F}

```



```{r, echo=T, message=F, warning=F}
plotErrors(errF)
plotErrors(errR)
```

Here, since we see fewer errors that are outliers with respect to the fitted error rates, we can resonably sure of the estimation by the parameterized model.  


```{r echo=T, message=F, warning=F}
dadaFs <- dada(derepFs, err=errF, multithread = T, USE_QUALS=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread = T, USE_QUALS=TRUE)
```



```{r, echo=T, message=F, warning=F}

```

Inspecting the dada class object returned by dada

```{r echo=T, message=F, warning=F}
dadaFs[[1]]
```
The DADA2 algorithm inferred 128 real sequence variants from the 1979 unique sequences in the first sample. The dada-class object contains multiple diagnostics about the quality of each inferred sequence variant(see help("dada-class") for some info).

Now , that the DADA2 sequence inference step removed most substitution and indel errors, (Benjamin J Callahan et al. 2016), we can merge the inferred  forward and reverse squences and remove paired sequences that do not perfectly overlap as a last step in quality control of errors. 

```{r, echo=T, message=F, warning=F}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs)
```

# Construct sequence table and remove chimeras:
he DADA2 method produces a sequence table that is a higher-resolution analogue of the common “OTU table” (operational taxonomic units), i.e. a sample by sequence feature table valued by the number of times each sequence was observed in each sample.

```{r echo=T, message=F, warning=F}
seqtabAll <- makeSequenceTable(mergers[!grepl("Mock", names(mergers))])
table(nchar(getSequences(seqtabAll)))


# Save and retrieve the seq table
# saveRDS(seqtabAll, file = "microbiome.rds")
# seqtabAll <- readRDS("microbiome.rds")
```

Since the error model that we used above does not account for chimeric components, we remove them by comparing every inferred sequence to others in the table, and removing the ones that have partial compliments to others sequences. 

```{r, echo=T, message=F, warning=F}
seqtabNoC <- removeBimeraDenovo(seqtabAll)
```

Based on the numbers of sequences before and after removal of the chimeric sequences, they make up for 22% of the infered sequence variants. They however make up for no more than 4% of total sequence reads. 

# Assign Taxonomy:
By sequencing 16srRNA genes, we can taxonomically classify sequence variants. By using the naive Bayesian classifier method (Wang et al. 2007), sequence variants are compared to a set of classified sequences for training. Here we use RDP v16 training set (Cole et al. 2009). For fungal taxonomy, the General Fasta release files from the [UNITE ITS database](https://unite.ut.ee/repository.php) can be used without any modification. 

```{r echo=T, message=F, warning=F}
fastaRef <- "../data/MiSeq_SOP/rdp_train_set_16.fa.gz"
taxTab <- assignTaxonomy(seqtabNoC, refFasta = fastaRef, multithread = T)
unname(head(taxTab))
```

# Construct a Phylogenetic tree:
Using the DECIPHER package, we use the sequences found after removing the chimeras to perform multiple alignment for constructing a phylogenetic tree. The sequence inference method we used does not use a reference, so we construct the phylogenetic tree de novo. First we use ```DECIPHER``` for multiple alignment and then use ```phangorn``` to contruct a phylogenetic tree. We construct the neighbourhood joining tree first and then fit a GTR+G+I (Generalized time reviersible with Gamma rate variation) maximum likelihood tree using the neighbour-joining tree as the initiating point. 


```{r, echo=T, message=F, warning=F}
seqs <- getSequences(seqtabNoC)
names(seqs) <- seqs
alignment <- DECIPHER::AlignSeqs(DNAStringSet(seqs), anchor=NA, verbose = F)
```



```{r echo=T, message=F, warning=F}
phangAlign <- phyDat(as(alignment, "matrix"), type = "DNA")
dm <- dist.ml(phangAlign)
treeNJ <- NJ(dm) 
fit = pml(treeNJ, data = phangAlign)
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model = "GTR", optInv = T, optGamma = T,
                    rearrangement = "stochastic", control = pml.control(trace = 0))
detach("package:phangorn", unload = T)
```
# Combine the data into Phyloseq object: 
The package ```phyloseq``` organizes and synthesizes the different data types from a typical amplicon sequencing experiment into a single data object that can be easily manipulated. The sample data is downloaded from github:
```{r, echo=T, message=F, warning=F}
samdf <- read.csv("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/MIMARKS_Data_combined.csv",header=TRUE)
samdf$SampleID <- paste0(gsub("00", "", samdf$host_subject_id), "D", samdf$age-21)
samdf <- samdf[!duplicated(samdf$SampleID),] # Remove dupicate entries for reverse reads
rownames(seqtabAll) <- gsub("124", "125", rownames(seqtabAll)) # Fix discrepancy # Can be commented for other data
all(rownames(seqtabAll) %in% samdf$SampleID) # Should be TRUE

```



```{r echo=F, message=F, warning=F}

# The links: https://bioconductor.org/help/course-materials/2017/BioC2017/Day1/Workshops/Microbiome/MicrobiomeWorkflowII.html

# https://f1000research.com/articles/5-1492/v2


```



```{r echo=T, message=F, warning=F}
rownames(samdf) <- samdf$SampleID
keep.cols <- c("collection_date", "biome", "target_gene", "target_subfragment",
"host_common_name", "host_subject_id", "age", "sex", "body_product", "tot_mass",
"diet", "family_relationship", "genotype", "SampleID") 
samdf <- samdf[rownames(seqtabAll), keep.cols]
```

All the data needed for this analysis including the sequence feature table, metadata, taxonomy information and phylogenetic tree are combines into an object. 

```{r, echo=T, message=F, warning=F}
ps <- phyloseq(otu_table(seqtabNoC, taxa_are_rows = F),
               sample_data(samdf),
               tax_table(taxTab), phy_tree(fitGTR$tree))
ps <- prune_samples(sample_names(ps) != "Mock", ps) # Remove the "Mock" sample
ps
```

# Using phyloseq:
```phyloseq``` is an R package which uses S4 data class to analyse amplicon-seq data. Additional information about the package can be found at [phyloseq homepage](https://joey711.github.io/phyloseq/). The dada sequence processing was run on the large dataset that is stored on Github and is downloaded as follows. 

```{r echo=T, message=F, warning=F}
ps_connect <- url("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/ps.rds")
ps = readRDS(ps_connect)
ps
```

# Filtering 
```phyloseq``` has tools for filtering, subsetting and grouping data. While this can be used to group the data according to taxa, it can also be used to remove noise.

# Taxonomic filtering
For many experiments, all organisms are well represented in available taxonomic reference databases. In these conditions, the ambiguous features that cannot be assigned to any high rank taxonomy are usually sequence artifacts that do not exist in nature, and are filtered out. However, for poorly charachterized specimens or novel samples, it is important to rule out the possibility of taxonomic novelty before filtering these sequences. This can be done at various taxon leves as mentioned below.

```{r, echo=T, message=F, warning=F}
# Show available ranks in dataset
rank_names(ps)
```

Here we consider rank phylum and create a table of read counts for each phylum present. 

```{r, echo=T, message=F, warning=F}
# create a table with number of features for each phyla
table(tax_table(ps)[, "Phylum"], exclude=NULL)
```

The phyla for which only one feature is observed can be filtered out. The features that are annotated with NA can also be filtered out, as they may be artifacts. We also filter out features with ambiguous annotations.

```{r echo=T, message=F, warning=F}
ps <- subset_taxa(ps, !is.na(Phylum) & !Phylum %in% c("", "uncharachterized"))
```

We should also explore the prevelance in the dataset where we see the number of samples in which a phylum is seen atleast once. We calculate the mean and total prevalence of each phylum.

```{r, echo=T, message=F, warning=F}
# Compute prevelance of each feature
prevdf = apply(X = otu_table(ps),
               MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2),
               FUN = function(x) {sum(x>0)})

# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(ps),
                    tax_table(ps))

plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})
```

With this table, we can decide which taxa we can filter out. Here Fusobacteria have appeared in only 2 samples and _Deinococcus thermus_ is seen in only 1% of all samples. So we can filter these out. In some cases, it might be useful to not filter them out, but here we will. 

```{r, echo=T, message=F, warning=F}
# Define phyla to filter
filterPhyla = c("Fusobacteria", "Deinococcus-Thermus")
# Filter entries with unidentified Phylum.
ps1 = subset_taxa(ps, !Phylum %in% filterPhyla)
ps1
```

We now visualize prevalence in each phyla for exploratory analysis. 

```{r echo=T, message=F, warning=F}
# Subset to the remaining phyla
prevdf1 = subset(prevdf, Phylum %in% get_taxa_unique(ps1, "Phylum"))
ggplot(prevdf1, aes(TotalAbundance, Prevalence/nsamples(ps), color=Phylum)) +
  # Include a guess for parameter
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) +
  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +
  xlab("Total Abundance") +
  ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) +
  theme(legend.position="none")
```

Note that each point in the figure above represents a different taxa. So we see maximum representation from Firmicutes in this data that we can explore more. 

```{r, echo=T, message=F, warning=F}
# Define prevalence threshold as 5% of total samples
prevalenceThreshold = 0.05 * nsamples(ps)
prevalenceThreshold
```



```{r echo=T, message=F, warning=F}
# Execute prevalence filter, using `prune_taxa()` function
keepTaxa = rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
ps2 = prune_taxa(keepTaxa, ps)
```
https://bioconductor.org/help/course-materials/2017/BioC2017/Day1/Workshops/Microbiome/MicrobiomeWorkflowII.html#using_phyloseq
## Agglomerate Taxa
Now we agglomerate the taxa in closely related genuses. 

```{r, echo=T, message=F, warning=F}
# How many genera would be present after filtering?
length(get_taxa_unique(ps2, taxonomic.rank = "Phylum"))

ps3 = tax_glom(ps2, "Genus", NArm = TRUE)
```



```{r echo=T, message=F, warning=F}
h1 = 0.4
ps4 = tip_glom(ps2, h = h1)
```



```{r, echo=T, message=F, warning=F}
multiPlotTitleTextSize = 15
p2tree = plot_tree(ps2, method = "treeonly",
                   ladderize = "left",
                   title = "Before Agglomeration") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p3tree = plot_tree(ps3, method = "treeonly",
                   ladderize = "left", title = "By Genus") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p4tree = plot_tree(ps4, method = "treeonly",
                   ladderize = "left", title = "By Height") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))

# group plots together
grid.arrange(nrow = 1, p2tree, p3tree, p4tree)
```



```{r echo=T, message=F, warning=F}
plot_abundance = function(physeq,title = "",
                          Facet = "Order", Color = "Phylum"){
  # Arbitrary subset, based on Phylum, for plotting
  p1f = subset_taxa(physeq, Phylum %in% c("Firmicutes"))
  mphyseq = psmelt(p1f)
  mphyseq <- subset(mphyseq, Abundance > 0)
  ggplot(data = mphyseq, mapping = aes_string(x = "sex",y = "Abundance",
                              color = Color, fill = Color)) +
    geom_violin(fill = NA) +
    geom_point(size = 1, alpha = 0.3,
               position = position_jitter(width = 0.3)) +
    facet_wrap(facets = Facet) + scale_y_log10()+
    theme(legend.position="none")
}
```



```{r, echo=T, message=F, warning=F}
# Transform to relative abundance. Save as new object.
ps3ra = transform_sample_counts(ps3, function(x){x / sum(x)})

plotBefore = plot_abundance(ps3,"")
plotAfter = plot_abundance(ps3ra,"")
# Combine each plot into one graphic.
grid.arrange(nrow = 2,  plotBefore, plotAfter)
```

# Subset by taxonomy

```{r echo=T, message=F, warning=F}
psOrd = subset_taxa(ps3ra, Order == "Lactobacillales")
plot_abundance(psOrd, Facet = "Genus", Color = NULL)
```

# Preprocessing

```{r, echo=T, message=F, warning=F}
qplot(sample_data(ps)$age, geom = "histogram",binwidth=20) + xlab("age")
```



```{r echo=T, message=F, warning=F}
qplot(log10(rowSums(otu_table(ps))),binwidth=0.2) +
  xlab("Logged counts-per-sample")
```



```{r, echo=T, message=F, warning=F}
sample_data(ps)$age_binned <- cut(sample_data(ps)$age,
                          breaks = c(0, 100, 200, 400))
levels(sample_data(ps)$age_binned) <- list(Young100="(0,100]", Mid100to200="(100,200]", Old200="(200,400]")
sample_data(ps)$family_relationship=gsub(" ","",sample_data(ps)$family_relationship)
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
out.wuf.log <- ordinate(pslog, method = "MDS", distance = "wunifrac")
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(pslog, out.wuf.log, color = "age_binned") +
  labs(col = "Binned Age") +
  coord_fixed(sqrt(evals[2] / evals[1]))
```



```{r echo=T, message=F, warning=F}
rel_abund <- t(apply(otu_table(ps), 1, function(x) x / sum(x)))
qplot(rel_abund[, 12], geom = "histogram",binwidth=0.05) +
  xlab("Relative abundance")
```

# Different Orientation projections

```{r, echo=T, message=F, warning=F}
outliers <- c("F5D165", "F6D165", "M3D175", "M4D175", "M5D175", "M6D175")
ps <- prune_samples(!(sample_names(ps) %in% outliers), ps)
```



```{r echo=T, message=F, warning=F}
which(!rowSums(otu_table(ps)) > 1000)
```



```{r, echo=T, message=F, warning=F}
ps <- prune_samples(rowSums(otu_table(ps)) > 1000, ps)
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
```



```{r echo=T, message=F, warning=F}
out.pcoa.log <- ordinate(pslog,  method = "MDS", distance = "bray")
evals <- out.pcoa.log$values[,1]
plot_ordination(pslog, out.pcoa.log, color = "age_binned",
                  shape = "family_relationship") +
  labs(col = "Binned Age", shape = "Litter")+
  coord_fixed(sqrt(evals[2] / evals[1]))
```



```{r, echo=T, message=F, warning=F}
out.dpcoa.log <- ordinate(pslog, method = "DPCoA")
evals <- out.dpcoa.log$eig
plot_ordination(pslog, out.dpcoa.log, color = "age_binned", label= "SampleID",
                  shape = "family_relationship") +
  labs(col = "Binned Age", shape = "Litter")+
  coord_fixed(sqrt(evals[2] / evals[1]))
```



```{r echo=T, message=F, warning=F}
plot_ordination(pslog, out.dpcoa.log, type = "species", color = "Phylum") +
  coord_fixed(sqrt(evals[2] / evals[1]))
```



```{r, echo=T, message=F, warning=F}
out.wuf.log <- ordinate(pslog, method = "PCoA", distance ="wunifrac")
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(pslog, out.wuf.log, color = "age_binned",
                  shape = "family_relationship") +
  coord_fixed(sqrt(evals[2] / evals[1])) +
  labs(col = "Binned Age", shape = "Litter")
```

## PCA on Ranks

```{r echo=T, message=F, warning=F}
abund <- otu_table(pslog)
abund_ranks <- t(apply(abund, 1, rank))
```



```{r, echo=T, message=F, warning=F}
abund_ranks <- abund_ranks - 329
abund_ranks[abund_ranks < 1] <- 1
```



```{r echo=T, message=F, warning=F}
abund_df <- melt(abund, value.name = "abund") %>%
  left_join(melt(abund_ranks, value.name = "rank"))
colnames(abund_df) <- c("sample", "seq", "abund", "rank")

abund_df <- melt(abund, value.name = "abund") %>%
  left_join(melt(abund_ranks, value.name = "rank"))
colnames(abund_df) <- c("sample", "seq", "abund", "rank")

sample_ix <- sample(1:nrow(abund_df), 8)
ggplot(abund_df %>%
         filter(sample %in% abund_df$sample[sample_ix])) +
  geom_point(aes(x = abund, y = rank, col = sample),
             position = position_jitter(width = 0.2), size = 1.5) +
  labs(x = "Abundance", y = "Thresholded rank") +
  scale_color_brewer(palette = "Set2")
```



```{r, echo=T, message=F, warning=F}
ranks_pca <- dudi.pca(abund_ranks, scannf = F, nf = 3)
row_scores <- data.frame(li = ranks_pca$li,
                         SampleID = rownames(abund_ranks))
col_scores <- data.frame(co = ranks_pca$co,
                         seq = colnames(abund_ranks))
tax <- tax_table(ps) %>%
  data.frame(stringsAsFactors = FALSE)
tax$seq <- rownames(tax)
main_orders <- c("Clostridiales", "Bacteroidales", "Lactobacillales",
                 "Coriobacteriales")
tax$Order[!(tax$Order %in% main_orders)] <- "Other"
tax$Order <- factor(tax$Order, levels = c(main_orders, "Other"))
tax$otu_id <- seq_len(ncol(otu_table(ps)))
row_scores <- row_scores %>%
  left_join(sample_data(pslog))
col_scores <- col_scores %>%
  left_join(tax)
```



```{r echo=T, message=FALSE, warning=FALSE}
evals_prop <- 100 * (ranks_pca$eig / sum(ranks_pca$eig))
ggplot() +
  geom_point(data = row_scores, aes(x = li.Axis1, y = li.Axis2), shape = 2) +
  geom_point(data = col_scores, aes(x = 25 * co.Comp1, y = 25 * co.Comp2, color =
                                    Order), size = .3, alpha = 0.6) +
  scale_color_brewer(palette = "Set2") +
  
  facet_grid(~ age_binned) +
  guides(col = guide_legend(override.aes = list(size = 3))) +
  labs(x = sprintf("Axis1 [%s%% variance]", round(evals_prop[1], 2)),
  y = sprintf("Axis2 [%s%% variance]", round(evals_prop[2], 2))) +
  coord_fixed(sqrt(ranks_pca$eig[2] / ranks_pca$eig[1])) +
  # theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)))
  theme_minimal()
```

# Cannonical correspondance

```{r, echo=T, message=F, warning=F}
ps_ccpna <- ordinate(pslog, "CCA", formula = pslog ~ age_binned + family_relationship)
```



```{r echo=T, message=F, warning=F}
library(ggrepel)
ps_scores <- vegan::scores(ps_ccpna)
sites <- data.frame(ps_scores$sites)
sites$SampleID <- rownames(sites)
sites <- sites %>%
  left_join(sample_data(ps))

species <- data.frame(ps_scores$species)
species$otu_id <- seq_along(colnames(otu_table(ps)))
species <- species %>%
  left_join(tax)
evals_prop <- 100 * ps_ccpna$CCA$eig[1:2] / sum(ps_ccpna$CA$eig)
```

```{r echo=T, message=F, warning=F}
ggplot() +
  geom_point(data = sites, aes(x = CCA1, y = CCA2), shape = 2, alpha = 0.5) +
  geom_point(data = species, aes(x = CCA1, y = CCA2, col = Order), size = 0.5) +
  geom_text_repel(data = species %>% filter(CCA2 < -2),
                    aes(x = CCA1, y = CCA2, label = otu_id),
            size = 1.5, segment.size = 0.1) +
  facet_grid(. ~ family_relationship) +
  guides(col = guide_legend(override.aes = list(size = 3))) +
  labs(x = sprintf("Axis1 [%s%% variance]", round(evals_prop[1], 2)),
       y = sprintf("Axis2 [%s%% variance]", round(evals_prop[2], 2))) +
  scale_color_brewer(palette = "Set2") +
  coord_fixed(sqrt(ps_ccpna$CCA$eig[2] / ps_ccpna$CCA$eig[1])*0.45) +
  # theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)))
  theme_minimal()
```

# Supervised learning

```{r, echo=T, message=F, warning=F}
library(caret)
sample_data(pslog)$age2 <- cut(sample_data(pslog)$age, c(0, 100, 400))
dataMatrix <- data.frame(age = sample_data(pslog)$age2, otu_table(pslog))
# take 8 mice at random to be the training set, and the remaining 4 the test set
trainingMice <- sample(unique(sample_data(pslog)$host_subject_id), size = 8)
inTrain <- which(sample_data(pslog)$host_subject_id %in% trainingMice)
training <- dataMatrix[inTrain,]
testing <- dataMatrix[-inTrain,]
plsFit <- train(age ~ ., data = training,
                method = "pls", preProc = "center")
```



```{r echo=T, message=F, warning=F}
plsClasses <- predict(plsFit, newdata = testing)
table(plsClasses, testing$age)
```



```{r, echo=T, message=F, warning=F}
library(randomForest)
rfFit <- train(age ~ ., data = training, method = "rf",
               preProc = "center", proximity = TRUE)
rfClasses <- predict(rfFit, newdata = testing)
table(rfClasses, testing$age)
```



```{r echo=T, message=F, warning=F}
pls_biplot <- list("loadings" = loadings(plsFit$finalModel),
                   "scores" = plsFit[["finalModel"]][["scores"]])
class(pls_biplot$scores) <- "matrix"

pls_biplot$scores <- data.frame(sample_data(pslog)[inTrain, ],
                                pls_biplot$scores)

tax <- tax_table(ps)@.Data %>%
  data.frame(stringsAsFactors = FALSE)
main_orders <- c("Clostridiales", "Bacteroidales", "Lactobacillales",
                 "Coriobacteriales")
tax$Order[!(tax$Order %in% main_orders)] <- "Other"
tax$Order <- factor(tax$Order, levels = c(main_orders, "Other"))
class(pls_biplot$loadings) <- "matrix"
pls_biplot$loadings <- data.frame(tax, pls_biplot$loadings)
```



```{r, echo=T, message=F, warning=F}
ggplot() +
  geom_point(data = pls_biplot$scores,
             aes(x = Comp.1, y = Comp.2), shape = 2) +
  geom_point(data = pls_biplot$loadings,
             aes(x = 25 * Comp.1, y = 25 * Comp.2, col = Order),
             size = 0.3, alpha = 0.6) +
  scale_color_brewer(palette = "Set2") +
  labs(x = "Axis1", y = "Axis2", col = "Binned Age") +
  guides(col = guide_legend(override.aes = list(size = 3))) +
  facet_grid( ~ age2) +
  # theme(panel.border = element_rect(color = "#787878", fill = alpha("white", 0)))
  theme_minimal()
```



```{r echo=T, message=F, warning=F}
rf_prox <- cmdscale(1 - rfFit$finalModel$proximity) %>%
  data.frame(sample_data(pslog)[inTrain, ])

ggplot(rf_prox) +
  geom_point(aes(x = X1, y = X2, col = age_binned),
             size = 1, alpha = 0.7) +
  scale_color_manual(values = c("#A66EB8", "#238DB5", "#748B4F")) +
  guides(col = guide_legend(override.aes = list(size = 4))) +
  labs(col = "Binned Age", x = "Axis1", y = "Axis2")
```



``` {r, echo=T, message=F, warning=F}
as.vector(tax_table(ps)[which.max(importance(rfFit$finalModel)), c("Family", "Genus")])
impOtu <- as.vector(otu_table(pslog)[,which.max(importance(rfFit$finalModel))])
maxImpDF <- data.frame(sample_data(pslog), abund = impOtu)
ggplot(maxImpDF) +   geom_histogram(aes(x = abund)) +
  facet_grid(age2 ~ .) +
  labs(x = "Abundance of discriminative bacteria", y = "Number of samples")
```



```{r, echo=T, message=F, warning=F}

net <- make_network(ps, max.dist=0.35, keep.isolates = FALSE)
sampledata <- data.frame(sample_data(ps))
V(net)$id <- sampledata[names(V(net)), "host_subject_id"]
V(net)$litter <- sampledata[names(V(net)), "family_relationship"]
# 
# ggplot(net, aes(x = x, y = y, xend = xend, yend = yend), layout = "fruchtermanreingold") +
#   geom_edges(color = "darkgray") +
#   geom_nodes(aes(color = id, shape = litter),  size = 3 ) +
#   theme(axis.text = element_blank(), axis.title = element_blank(),
#         legend.key.height = unit(0.5,"line")) +
#   guides(col = guide_legend(override.aes = list(size = .5)))
```



```{r echo=T, message=F, warning=F}
gt <- graph_perm_test(ps, "family_relationship", grouping = "host_subject_id",
                      distance = "jaccard", type = "mst")
gt$pval

plotNet1=plot_test_network(gt) + theme(legend.text = element_text(size = 8),
        legend.title = element_text(size = 9))
plotPerm1=plot_permutations(gt)
grid.arrange(ncol = 2,  plotNet1, plotPerm1)
```



```{r, echo=T, message=F, warning=F}
gt <- graph_perm_test(ps, "family_relationship", grouping = "host_subject_id",
                      distance = "jaccard", type = "knn", knn = 1)

plotNet2=plot_test_network(gt) + theme(legend.text = element_text(size = 8),
        legend.title = element_text(size = 9))
plotPerm2=plot_permutations(gt)
grid.arrange(ncol = 2,  plotNet2, plotPerm2)
```



```{r echo=T, message=F, warning=F}
ps_alpha_div <- estimate_richness(ps, split = TRUE, measure = "Shannon")
ps_alpha_div$SampleID <- rownames(ps_alpha_div) %>%
  as.factor()
ps_samp <- sample_data(ps) %>%
  unclass() %>%
  data.frame() %>%
  left_join(ps_alpha_div, by = "SampleID") %>%
  melt(measure.vars = "Shannon",
       variable.name = "diversity_measure",
       value.name = "alpha_diversity")

# reorder's facet from lowest to highest diversity
diversity_means <- ps_samp %>%
  group_by(host_subject_id) %>%
  summarise(mean_div = mean(alpha_diversity)) %>%
  arrange(mean_div)
ps_samp$host_subject_id <- factor(ps_samp$host_subject_id)
#                                  diversity_means$host_subject_id)
```



```{r echo=T, message=F, warning=F}
alpha_div_model <- lme(fixed = alpha_diversity ~ age_binned, data = ps_samp,
                       random = ~ 1 | host_subject_id)
```



```{r echo=T, message=F, warning=F}
new_data <- expand.grid(host_subject_id = levels(ps_samp$host_subject_id),
                        age_binned = levels(ps_samp$age_binned))
new_data$pred <- predict(alpha_div_model, newdata = new_data)
X <- model.matrix(eval(eval(alpha_div_model$call$fixed)[-2]),
                  new_data[-ncol(new_data)])
pred_var_fixed <- diag(X %*% alpha_div_model$varFix %*% t(X))
new_data$pred_var <- pred_var_fixed + alpha_div_model$sigma ^ 2
```



```{r echo=T, message=F, warning=F}
# fitted values, with error bars
ggplot(ps_samp %>% left_join(new_data)) +
  geom_errorbar(aes(x = age_binned, ymin = pred - 2 * sqrt(pred_var),
                    ymax = pred + 2 * sqrt(pred_var)),
                col = "#858585", size = .1) +
  geom_point(aes(x = age_binned, y = alpha_diversity,
                 col = family_relationship), size = 0.8) +
  facet_wrap(~host_subject_id) +
  scale_y_continuous(limits = c(2.4, 4.6), breaks = seq(0, 5, .5)) +
  scale_color_brewer(palette = "Set2") +
  labs(x = "Binned Age", y = "Shannon Diversity", color = "Litter") +
  guides(col = guide_legend(override.aes = list(size = 4))) +
  theme(axis.text.x = element_text(angle = -90, size = 6),
        axis.text.y = element_text(size = 6))
```



```{r echo=T, message=F, warning=F}
#New version of DESeq2 needs special levels
sample_data(ps)$age_binned <- cut(sample_data(ps)$age,
                          breaks = c(0, 100, 200, 400))
levels(sample_data(ps)$age_binned) <- list(Young100="(0,100]", Mid100to200="(100,200]", Old200="(200,400]")
sample_data(ps)$family_relationship = gsub(" ", "", sample_data(ps)$family_relationship)
ps_dds <- phyloseq_to_deseq2(ps, design = ~ age_binned + family_relationship)

# geometric mean, set to zero when all coordinates are zero
geo_mean_protected <- function(x) {
  if (all(x == 0)) {
    return (0)
  }
  exp(mean(log(x[x != 0])))
}

geoMeans <- apply(counts(ps_dds), 1, geo_mean_protected)
ps_dds <- estimateSizeFactors(ps_dds, geoMeans = geoMeans)
ps_dds <- estimateDispersions(ps_dds)
abund <- getVarianceStabilizedData(ps_dds)
```



```{r echo=T, message=F, warning=F}
short_names <- substr(rownames(abund), 1, 5)%>%
  make.names(unique = TRUE)
rownames(abund) <- short_names
```



```{r echo=T, message=F, warning=F}
abund_sums <- rbind(data.frame(sum = colSums(abund),
                               sample = colnames(abund),
                               type = "DESeq2"),
                    data.frame(sum = rowSums(otu_table(pslog)),
                               sample = rownames(otu_table(pslog)),
                               type = "log(1 + x)"))

ggplot(abund_sums) +
  geom_histogram(aes(x = sum), binwidth = 20) +
  facet_grid(type ~ .) +
  xlab("Total abundance within sample")
```

# Hierarcheal multi-testing:

```{r echo=T, message=F, warning=F}
el <- phy_tree(pslog)$edge
el0 <- el
el0 <- el0[nrow(el):1, ]
el_names <- c(short_names, seq_len(phy_tree(pslog)$Nnode))
el[, 1] <- el_names[el0[, 1]]
el[, 2] <- el_names[as.numeric(el0[, 2])]
unadj_p <- treePValues(el, abund, sample_data(pslog)$age_binned)

hfdr_res <- hFDR.adjust(unadj_p, el, .75)
summary(hfdr_res)

#interactive part: not run
plot(hfdr_res, height = 5000) # opens in a browser


tax <- tax_table(pslog)[, c("Family", "Genus")] %>%
  data.frame()
tax$seq <- short_names

options(digits=3)
hfdr_res@p.vals$seq <- rownames(hfdr_res@p.vals)
tax %>%
  left_join(hfdr_res@p.vals) %>%
  arrange(adjp) %>% head(10)
```

# Multitable techniques:

```{r echo=T, message=F, warning=F}
metab <- read.csv("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/metabolites.csv",row.names = 1)
microbe_connect <-url("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/microbe.rda")
load(microbe_connect)
microbe
```



```{r echo=T, message=F, warning=F}
keep_ix <- rowSums(metab == 0) <= 3
metab <- metab[keep_ix, ]
microbe <- prune_taxa(taxa_sums(microbe) > 4, microbe)
microbe <- filter_taxa(microbe, filterfun(kOverA(3, 2)), TRUE)
metab <- log(1 + metab, base = 10)
X <- otu_table(microbe)
X[X > 50] <- 50
dim(X)

dim(metab)
```



```{r echo=T, message=F, warning=F}
# cca_res <- CCA(t(X),  t(metab), penaltyx = .15, penaltyz = .15)
# cca_res
# 
# combined <- cbind(t(X[cca_res$u != 0, ]),
#                   t(metab[cca_res$v != 0, ]))
# pca_res <- dudi.pca(combined, scannf = F, nf = 3)
# 
# 
# genotype <- substr(rownames(pca_res$li), 1, 2)
# sample_type <- substr(rownames(pca_res$l1), 3, 4)
# feature_type <- grepl("\\.", colnames(combined))
# feature_type <- ifelse(feature_type, "Metabolite", "OTU")
# sample_info <- data.frame(pca_res$li, genotype, sample_type)
# feature_info <- data.frame(pca_res$c1,
#                            feature = substr(colnames(combined), 1, 6))
# 
# ggplot() +  geom_point(data = sample_info,
#             aes(x = Axis1, y = Axis2, col = sample_type, shape = genotype), size = 3) +
#   geom_label_repel(data = feature_info,
#                    aes(x = 5.5 * CS1, y = 5.5 * CS2, label = feature, fill = feature_type),
#                    size = 2, segment.size = 0.3,
#                    label.padding = unit(0.1, "lines"), label.size = 0) +
#   geom_point(data = feature_info,
#              aes(x = 5.5 * CS1, y = 5.5 * CS2, fill = feature_type),
#              size = 1, shape = 23, col = "#383838") +
#   scale_color_brewer(palette = "Set2") +
#   scale_fill_manual(values = c("#a6d854", "#e78ac3")) +
#   guides(fill = guide_legend(override.aes = list(shape = 32, size = 0))) +
#   coord_fixed(sqrt(pca_res$eig[2] / pca_res$eig[2])) +
#   labs(x = sprintf("Axis1 [%s%% Variance]",
#                    100 * round(pca_res$eig[1] / sum(pca_res$eig), 2)),
#        y = sprintf("Axis2 [%s%% Variance]",
#                    100 * round(pca_res$eig[2] / sum(pca_res$eig), 2)),
#        fill = "Feature Type", col = "Sample Type")
```



```{r echo=T, message=F, warning=F}
sessionInfo()
```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```



```{r echo=T, message=F, warning=F}

```
